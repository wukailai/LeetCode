jps：查看java进程状态信息； 
jstack：查看线程堆栈情况，可检查死锁；
jmap：查看堆内存使用情况；
jstat：查看堆使用和回收情况；
线程调用start()方式之后，线程处于Runnable状态，获取cpu执行时间才处于runnning状态；
在Daemon线程中产生的新线程也是Daemon的；
synchronized是可重入的非公平锁，系统自动解锁；
处于Contention List、Entry List、Wait List里面的线程都处于阻塞状态，阻塞操作是由操作系统完成的；
!Owner：当前释放锁的线程；
分锁机制优化synchronize；
safe point：这个时间点没有其他字节码正在执行；
偏向锁：只有第一次获得锁的时候才需要CAS（CAS的是偏向线程ID，同时修改是否为偏向锁0 -> 1），后续重入只需要向Lock Record插入一个空的Displace Mark Word即可；
对象头信息：Mark Word，记录了锁相关信息，锁标志位（00（轻量级），10（重量级），01（无锁或者偏向锁），11（GC））、是否可偏向（0，1）、偏向线程ID、HashCode、GC年龄；
轻量级锁：栈帧创建Lock Record，用于存放Mark Word的拷贝，每次加锁，拷贝Mark Word到Lock Record（Displace Mark Word的owner和对象头的stack pointer相互指向）；
轻量级锁升级为重量级锁：后来的线程CAS+有次数的自旋失败，修改了对象头的Mark Word（00 -> 10），Owner占有锁的时候进行升级操作；
锁粗化使用场景：循环内部加锁 --> 直接在循环外部加锁；
重量级锁：指向互斥量的指针；
偏向锁只有在出现撤销偏向锁时才会执行释放锁操作；
轻量级锁有两种：自旋锁；适应性自旋锁；
synchronized非公平体现：1）线程在进入Contention List之前会先尝试自旋获取锁，获取失败才进入Contention List、2）成为OnDeck线程的随机性；
synchronized加锁就是在竞争对象监视器，重量级操作（需要在用户态和系统态之间切换，依赖于操作系统Mutex Lock），需要调用系统相关接口；
AtomicReference<V>：将一个对象的所有操作转化成原子操作；AtomicStampedReference；
AtomicStampedReference<V>：可以解决ABA问题；
onDeck线程由释放锁的线程从Entry List中指定，onDeck线程只是拥有竞争锁的权利；
锁的状态总共有四种：无锁状态、
					偏向锁（偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起来让这个线程得到了偏护，只有一个线程竞争锁的时候用到，
					如果有两个或者两个以上的线程在竞争同一把锁，则会在safe point（stop world并挂起owner）执行偏向锁撤销操作，
					偏向锁也会升级为轻量级锁（释放owner），进行CAS竞争锁）、
					轻量级锁（依赖CAS）、
					重量级锁；
wait() -> 线程进入WAITING状态、sleep() -> 线程进入TIMED_WAITING状态；
ArrayBlockingQueue区分公平性和非公平性，具体体现在ReentrantLock成本变量身上；
CyclicBarrier一般用于一组线程互相等待至某个状态；
底层实现不一样，synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略；
让出CPU：a）yield、b）IO阻塞；c）线程执行结束；
动态语言，是指程序在运行时可以改变其结构；
java中的反射机制是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法。并且对于任意一个对象，都能够调用它的任意一个方法；
java反射简单来说：运行时状态下动态获取类信息，动态调用对象方法；
Java程序中许多对象在运行时都会出现两种类型：编译时类型和运行时类型：编译时的类型由声明对象时实用的类型来决定，运行时的类型由实际赋值给对象的类型决定；
可以通过反射来获取注解；
泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型，泛型的本质是参数化类型；
泛型擦除实现：首先是找到用来替换类型参数的具体类。这个具体类一般是Object。如果指定了类型参数的上界的话，则使用这个上界，把代码中的类型参数都替换 成具体的类；
序列化用字节数组来保存，序列化保存的是状态，所以静态变量不会被序列化；
序列化ID决定着是否可以反序列化成功（ObjectInputStream）：比较字节流中的序列化ID是否和本地实体类中的序列化ID一致；
交换机--数据链路层--数据帧--MAC地址；路由--网络层（IP协议）--数据包--IP地址；
传输层：定义传输数据的协议（TCP、UDP）和端口号--报文段；会话层：建立数据传输通道；表示层：解密、加密，压缩、解压；应用层：FTP、HTTP；
HTTPS默认端口：443；
数据库一个page占64KB；
MyISAM：适用于只读场景，读取速度更快；
索引列不能参与计算，否则索引会失效；
数据库第二范式理解：表需要有主键，并且其他表字段需要依赖于这个主键；
数据库第三范式理解：每列都和主键直接相关，而不是间接相关；
存储过程：一组SQL集，第一次调用编译，编译结果存放在缓存中，后面不需要再编译；
数据库并发策略：乐观锁、悲观锁、时间戳；
表级锁：共享读锁，写独占锁；
页级锁：介于行级锁（太慢）和表级锁（冲突多）之间，锁住相邻的一组记录；
Redis分布式锁：set key value（随机UUID，可识别锁），并expire设置一个超时时间自动释放锁，手动释放锁delete；
垂直切分：数据库表（访问频率一致的一起、经常一起访问的一起）部署到不同数据库上；
水平切分：数据量太大时，将数据记录按照一定规则（比如散列）分配到相同结构不同表、甚至不同库上；
红黑树：一种特殊的二叉查找树，节点区分红黑两种节点；
jvm对synchronize优化：
    1）适应性自旋（由CPUs负载+上一次自旋时间+锁拥有者状态决定，默认一个线程切换上下文时间，如果自旋线程上一次或者之前成功自旋获取到过锁，
    那么线程自旋等待时间会比较长，之前自旋成功获取锁比较少，则会等待时间比较短，甚至直接阻塞）；
    2）分锁机制，引入了偏向锁、轻量级锁；
数组对象对象头会存储数组长度；
CAS底层原理实现：
    UnSafe类，java无法直接访问底层，但可以通过native方法来访问；
    Compare-And-Swap，它是一条CPU并发原语；
volatile底层实现原理：
    jmm模型，每个java线程都有一个私有的本地内存，该内存保存着共享变量的副本，多线程之间可以通过共享内存实现线程之间的通信；
    被volatile修饰的变量执行写操作刷新到主内存后（使用Lock前缀指令），会让其他线程本地内存的数据失效（嗅探技术），进而去主内存去读取最新的数据；
对象头=Mark Word + 类型指针（指向对象的类元数据，jvm根据类型指针确定对象是哪个类的实例）
java对象=对象头 + 实例数据 + 填充数据（JVM要求java的对象占的内存大小应该是8bit的倍数）；
管道流主要用于在不同线程间直接传送数据，管道是一段有大小限制的内存，线程可以将数据写入管道，也可以从管道中读取数据；
MemCache：支持的数据结构比较少，且不支持持久化；
Redis：数据全内存，虽然读取快，但是需要考虑资源成本，访问Redis会有IO、序列化、反序列化开销；
Tair：理论上可以无限扩容；
如果有数据更新：1）先删除缓存，再更新数据库（删除缓存后，更新数据库之前会导致读到数据库老的数据）；
             2）先更新数据库，再删除缓存（推荐，导致的问题：缓存没有命中，读到旧值，更新数据库 + 删除缓存，再将旧值回填到缓存，造成缓存和数据库不一致）；
             注意：这里不能更新缓存，因为在并发场景下并不能保证缓存、数据更新顺序一致；
解决缓存穿透问题：null也做缓存；
解决缓存击穿问题：改到期自动淘汰为自动刷新（仅针对热点数据），或者加分布式锁，保证获得锁的线程执行完数据库查询 + 填充缓存操作，其他线程采取重试机制；
解决缓存雪崩问题：多级缓存，不同级别缓存过期时间不一致，过期时间随机性；

IO、NIO、poll、epoll不熟；
特殊的阻塞队列；
volatile底层实现；
java注解；
Spring原理；
微服务；
Netty与RPC；
ZooKeeper；
Kafka；
RabbitMQ；
HBase；
MongoDB；
Cassandra；
设计模式；
负载均衡；
基于Redis分布式锁；
两段提交协议；
三阶段提交协议；
柔性事务；
CAP；
一致性算法；
回溯算法；最短路径算法；最大子数组算法；最长公共子序算法；最小生成树算法；
红黑树；
位图；
缓存降级；
Hadhoop；
Spark；
Storm；
YARN；
机器学习；
云计算；